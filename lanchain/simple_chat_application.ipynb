{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the key.\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(groq_api_key = groq_api_key, model = \"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Prompt: \n",
      " Human: Translate the I would like to work with the person with whom I was living for a week. in German\n",
      "Response from LLM: \n",
      "content='Here are a few ways to translate \"I would like to work with the person with whom I was living for a week\" into German, capturing different levels of formality:\\n\\n**Formal:**\\n\\n* **Ich möchte mit der Person zusammenarbeiten, mit der ich die vergangenen Woche gewohnt habe.** (This is the most literal translation and uses formal language.)\\n\\n**Less Formal:**\\n\\n* **Ich würde gerne mit demjenigen zusammenarbeiten, mit dem ich die letzte Woche zusammengelebt habe.**\\n* **Ich möchte mit demjenigen, bei dem ich letzte Woche gewohnt habe, zusammenarbeiten.** (This version is shorter and more concise.)\\n\\n**Informal:**\\n\\n* **Ich will mit dem/der, mit dem/der ich die Woche zusammen gewohnt habe, zusammenarbeiten.**\\n\\n\\nChoose the option that best suits the context and your relationship with the person you\\'re addressing. \\n\\n\\n' response_metadata={'token_usage': {'completion_tokens': 179, 'prompt_tokens': 32, 'total_tokens': 211, 'completion_time': 0.325454545, 'prompt_time': 0.000355968, 'queue_time': 0.013937951, 'total_time': 0.325810513}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-1682eeb1-854c-4d2d-b4a2-7777747b0916-0' usage_metadata={'input_tokens': 32, 'output_tokens': 179, 'total_tokens': 211}\n"
     ]
    }
   ],
   "source": [
    "template = \"Translate the {text} in {language}\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Define the input variables\n",
    "input = {\n",
    "    \"text\": \"I would like to work with the person with whom I was living for a week.\",\n",
    "    \"language\": \"German\"\n",
    "}\n",
    "\n",
    "# Format the prompt with the input variables\n",
    "final_prompt_1 = prompt.format(**input)\n",
    "print(f\"Formatted Prompt: \\n {final_prompt_1}\")\n",
    "\n",
    "# Prepare the structured message for the LLM\n",
    "messages = [{\"role\": \"user\", \"content\": final_prompt_1}]\n",
    "\n",
    "# Call the LLM with the properly structured messages\n",
    "response = llm.invoke(input = messages)\n",
    "print(f\"Response from LLM: \\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "\n",
      "Second way of defining the input varibles: \n",
      "Human: Translate the I would like to work with the person with whom I was living for a week. in German\n",
      "Here are a few ways to translate \"I would like to work with the person with whom I was living for a week\" in German, with varying degrees of formality:\n",
      "\n",
      "**Formal:**\n",
      "\n",
      "* **Ich würde gerne mit der Person zusammenarbeiten, mit der ich die letzte Woche zusammen gewohnt habe.** \n",
      "\n",
      "**Informal:**\n",
      "\n",
      "* **Ich möchte gerne mit demjenigen zusammenarbeiten, mit dem ich die Woche gewohnt habe.**\n",
      "* **Ich würde mit demjenigen gerne zusammenarbeiten, mit dem ich die Woche zusammen gewohnt habe.**\n",
      "\n",
      "**Note:**\n",
      "\n",
      "* **Zusammenarbeiten** means \"to work together\"\n",
      "* **Die letzte Woche** means \"the last week\"\n",
      "* **Die Woche** means \"the week\"\n",
      "* It's important to choose the right level of formality depending on the context.\n",
      "\n",
      "\n",
      "Let me know if you have any other phrases you'd like translated!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"************************************************************************************************************************\\n\")\n",
    "# second way of defining the input varibles\n",
    "final_prompt_2 = prompt.format(text = \"I would like to work with the person with whom I was living for a week.\", language = \"German\")\n",
    "\n",
    "print(f\"Second way of defining the input varibles: \\n{final_prompt_2}\")\n",
    "\n",
    "# create the input message in the llm format\n",
    "messages = [{\"role\":\"user\", \"content\": final_prompt_2}]\n",
    "response = llm.invoke(input = messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "\n",
      "Third way of defining the input varibles: \n",
      "You are a German language expert, Translate Sentence in German: I would like to work with the person with whom I was living for a week.\n",
      "The sentence is a bit awkward in English, so there are a few ways to translate it smoothly into German. Here are two options:\n",
      "\n",
      "**Option 1 (More formal):**\n",
      "\n",
      "> Ich würde gerne mit der Person zusammenarbeiten, mit der ich die letzte Woche zusammen gewohnt habe.\n",
      "\n",
      "**Option 2 (More casual):**\n",
      "\n",
      "> Ich möchte mit dem/derjenigen zusammenarbeiten, mit dem/der ich die letzte Woche zusammen gewohnt habe.\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "* **\"Ich würde gerne...\"** means \"I would like...\"\n",
      "* **\"mit der/dem Person...\"** means \"with the person...\" (Use \"der\" for masculine, \"die\" for feminine, and \"das\" for neuter)\n",
      "* **\"...mit der ich die letzte Woche zusammen gewohnt habe\"** means \"...with whom I lived for the last week.\" \n",
      "\n",
      "\n",
      "Let me know if you have any other sentences you'd like translated!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"************************************************************************************************************************\\n\")\n",
    "# Third way of defining the input varibles\n",
    "template_1 = (\"You are a {0} language expert, Translate Sentence in {0}: {1}\")\n",
    "final_prompt_3 = template_1.format(\"German\", \"I would like to work with the person with whom I was living for a week.\")\n",
    "print(f\"Third way of defining the input varibles: \\n{final_prompt_3}\")\n",
    "\n",
    "# create the input message to llm model\n",
    "messages = [{\"role\" : \"user\", \"content\": final_prompt_3}]\n",
    "response = llm.invoke(input = messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are the expert and consultant in the field of education. I would like you to list the top 10 universities from Germany.\n",
      "                                Output format must be:\n",
      "                                University_first = name1\n",
      "                                University_second = name2\n",
      "                                ...\n",
      "                                University_Tenth = name10\n",
      "                                .\n",
      "\n",
      "                                Also answer question for wach university: ['why these university is famous?', 'what is the world ranking of this university?', 'which are the courses tought at this university?'].\n",
      "It's impossible for me to definitively say which are the \"top 10\" universities in Germany because rankings are subjective and depend on the criteria used. Different organizations prioritize different factors like research output, academic reputation, student satisfaction, and more. \n",
      "\n",
      "However, I can give you a list of 10 highly respected and renowned German universities, along with some information about them:\n",
      "\n",
      "**University_First** = Ludwig-Maximilians-Universität München (LMU Munich)\n",
      "* **Why famous?**  LMU Munich is one of Germany's oldest and largest universities, known for its strong research focus across various disciplines, especially humanities, law, and medicine.\n",
      "* **World Ranking:**  Consistently ranks in the top 100 globally (e.g., QS World University Rankings, Times Higher Education World University Rankings).\n",
      "* **Courses:**  Offers a wide range of undergraduate and graduate programs in fields like Arts & Humanities, Business & Economics, Law, Medicine, Natural Sciences, and Engineering.\n",
      "\n",
      "**University_Second** = Technische Universität München (TUM)\n",
      "* **Why famous?** TUM is a leading technical university, renowned for its excellence in engineering, natural sciences, and computer science. It has a strong focus on innovation and entrepreneurship.\n",
      "* **World Ranking:**  Also consistently ranks in the top 100 globally.\n",
      "* **Courses:**  Specializes in engineering, natural sciences, computer science, and related fields.\n",
      "\n",
      "**University_Third** =  Heidelberg University\n",
      "* **Why famous?**  One of the oldest universities in Europe, Heidelberg is known for its rich history, beautiful campus, and strong research in humanities, law, and social sciences.\n",
      "* **World Ranking:**  Ranks highly in global rankings, particularly for humanities and social sciences.\n",
      "* **Courses:**  Offers a wide range of programs in arts & humanities, law, medicine, natural sciences, and social sciences.\n",
      "\n",
      "**University_Fourth** = Universität Freiburg\n",
      "* **Why famous:**  Known for its strong research focus, especially in medicine, law, and the humanities. It has a beautiful historic campus and a vibrant student life.\n",
      "* **World Ranking:**  Consistently ranked among the top universities in Germany.\n",
      "* **Courses:**  Offers a diverse range of programs, including medicine, law, theology, humanities, social sciences, and natural sciences.\n",
      "\n",
      "**University_Fifth** = Humboldt-Universität zu Berlin\n",
      "* **Why famous:**  A historical university known for its contributions to philosophy, history, and the sciences. It has a strong academic reputation and a large international student body.\n",
      "* **World Ranking:**  Ranks highly in global university rankings.\n",
      "* **Courses:**  Offers a wide range of programs in humanities, social sciences, natural sciences, and the arts.\n",
      "\n",
      "**University_Sixth** =  RWTH Aachen University\n",
      "* **Why famous:**  A leading technical university with a strong emphasis on engineering, computer science, and applied sciences. \n",
      "* **World Ranking:**  Highly ranked for its technical and engineering programs.\n",
      "* **Courses:**  Focuses primarily on engineering, computer science, natural sciences, and related fields.\n",
      "\n",
      "**University_Seventh** =  Universität Tübingen \n",
      "* **Why famous:**  Known for its excellence in humanities, theology, law, and medicine. \n",
      "* **World Ranking:**  Ranks among the top universities in Germany.\n",
      "* **Courses:**  Offers a wide range of programs across diverse disciplines, including  law, medicine, theology, and humanities.\n",
      "\n",
      "**University_Eighth** =  Universität Bonn\n",
      "* **Why famous:**  A long-standing university with a strong reputation in humanities, social sciences, and natural sciences.\n",
      "* **World Ranking:**  Consistently ranked among Germany's top universities.\n",
      "* **Courses:**  Offers a broad range of programs across various disciplines.\n",
      "\n",
      "**University_Ninth** =  Universität Göttingen\n",
      "* **Why famous:**  Historically significant university known for its contributions to science and research.\n",
      "* **World Ranking:**  Ranks highly in global university rankings.\n",
      "* **Courses:**  Offers a diverse range of programs in humanities, social sciences, natural sciences, and the arts.\n",
      "\n",
      "**University_Tenth** =  Universität Leipzig\n",
      "* **Why famous:**  One of Germany's oldest universities, known for its strong humanities and social sciences programs.\n",
      "* **World Ranking:**  Ranks among the top universities in Germany.\n",
      "* **Courses:**  Offers a wide range of programs across various disciplines, with a particular emphasis on humanities and social sciences.\n",
      "\n",
      "\n",
      "\n",
      "Remember that this is just a small sample, and many other excellent universities exist in Germany.  \n",
      "\n",
      "I recommend you research universities based on your specific academic interests and career goals. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate the college information.\n",
    "country = \"Germany\"\n",
    "\n",
    "questions = [\"why these university is famous?\", \n",
    "             \"what is the world ranking of this university?\",\n",
    "             \"which are the courses tought at this university?\"]\n",
    "\n",
    "\n",
    "# define the multiline input prompt\n",
    "input_prompt = \"\"\"You are the expert and consultant in the field of education. I would like you to list the top 10 universities from {country}.\n",
    "                                Output format must be:\n",
    "                                University_first = name1\n",
    "                                University_second = name2\n",
    "                                ...\n",
    "                                University_Tenth = name10\n",
    "                                .\n",
    "\n",
    "                                Also answer question for wach university: {questions}.\"\"\"\n",
    "\n",
    "\n",
    "# Define the prompt template\n",
    "initial_prompt = PromptTemplate(template=input_prompt, input_variables=[\"country\", \"questions\"])\n",
    "\n",
    "filled_prompt = initial_prompt.format(country=country, questions=questions)\n",
    "\n",
    "print(filled_prompt)\n",
    "\n",
    "response = llm.invoke(input = filled_prompt)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with message history\n",
    "\n",
    "template = \"You are the helpful assistant. Please answer the user question.\"\n",
    "\n",
    "\n",
    "prompt_templete = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", template),\n",
    "     MessagesPlaceholder(variable_name=\"history\"),\n",
    "     (\"human\", \"{query}\")]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt_templete,\n",
    "    memory = memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(memory=ConversationBufferMemory(return_messages=True), prompt=ChatPromptTemplate(input_variables=['history', 'query'], input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are the helpful assistant. Please answer the user question.')), MessagesPlaceholder(variable_name='history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}'))]), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001C14EC83700>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001C14EC749D0>, model_name='gemma2-9b-it', groq_api_key=SecretStr('**********')))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
